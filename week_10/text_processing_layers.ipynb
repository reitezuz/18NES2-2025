{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reitezuz/18NES2-2025/blob/main/week_10/text_processing_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextVectorization layer\n",
        "https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/"
      ],
      "metadata": {
        "id": "YkMIXyL-RP6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ],
      "metadata": {
        "id": "NqFbf3_8xjTA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text vectorization with default standardization and split\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "'''\n",
        "keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\", # default standardization\n",
        "    split=\"whitespace\",                        # default split\n",
        "    ngrams=None,                               # None, 2, 3,...\n",
        "    output_mode=\"int\",                         # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    idf_weights=None,\n",
        "    sparse=False,\n",
        "    ragged=False,\n",
        "    encoding=\"utf-8\",\n",
        "    name=None,\n",
        "    **kwargs\n",
        ")\n",
        "'''\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "   )\n"
      ],
      "metadata": {
        "id": "2VlIZpRkwEoL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IMvZtIYivNSk"
      },
      "outputs": [],
      "source": [
        "# Text vectorization with custom standardization and custom split\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor) # to lowercase\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")  # remove punctuation\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor) # split by whitespace\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the vocabulary:"
      ],
      "metadata": {
        "id": "ararNlBxTgil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    \"The weather today is surprisingly warm.\",\n",
        "    \"Tomorrow will be much colder, according to the forecast.\",\n",
        "    \"Warm days in winter are unusual, but not impossible.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)\n"
      ],
      "metadata": {
        "id": "6skq5HIPvgYr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary:\n",
        "- word order is based on their frequency:"
      ],
      "metadata": {
        "id": "Ra28HqkrS5wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn1llI1ivnen",
        "outputId": "9859df80-1cbe-4f7a-8886-bf04b688e7e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('warm'),\n",
              " np.str_('the'),\n",
              " np.str_('winter'),\n",
              " np.str_('will'),\n",
              " np.str_('weather'),\n",
              " np.str_('unusual'),\n",
              " np.str_('tomorrow'),\n",
              " np.str_('today'),\n",
              " np.str_('to'),\n",
              " np.str_('surprisingly'),\n",
              " np.str_('not'),\n",
              " np.str_('much'),\n",
              " np.str_('is'),\n",
              " np.str_('in'),\n",
              " np.str_('impossible'),\n",
              " np.str_('forecast'),\n",
              " np.str_('days'),\n",
              " np.str_('colder'),\n",
              " np.str_('but'),\n",
              " np.str_('be'),\n",
              " np.str_('are'),\n",
              " np.str_('according')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize text:\n",
        "- OOV (out-of-vocabulary) words have index 1"
      ],
      "metadata": {
        "id": "77vV7KEjTAcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb_kMZXFv1ni",
        "outputId": "2d88b753-73c2-4745-e917-f4485ce571ee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  6  9 14  2 20  1 14  1  7  6  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different vectorization modes"
      ],
      "metadata": {
        "id": "hd73TMUt3u6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\", # default standardization\n",
        "    split=\"whitespace\",                        # default split, can be \"character\"\n",
        "    ngrams=None,                               # None, 2, 3,...\n",
        "    output_mode=\"int\",                         # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    idf_weights=None,\n",
        "    sparse=False,\n",
        "    ragged=False,\n",
        "    encoding=\"utf-8\",\n",
        "    name=None,\n",
        "    **kwargs\n",
        ")\n",
        "'''\n",
        "\n",
        "text_vectorization_1 = TextVectorization(\n",
        "    output_mode=\"multi_hot\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "   )\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n"
      ],
      "metadata": {
        "id": "WFgJLI322RVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f979d22f-5d6e-4b55-ee16-5b44c26b1f62"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter'), np.str_('will'), np.str_('weather'), np.str_('unusual'), np.str_('tomorrow'), np.str_('today'), np.str_('to'), np.str_('surprisingly'), np.str_('not'), np.str_('much'), np.str_('is'), np.str_('in'), np.str_('impossible'), np.str_('forecast'), np.str_('days'), np.str_('colder'), np.str_('but'), np.str_('be'), np.str_('are'), np.str_('according')] \n",
            " 23\n",
            "[1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of tokenization techniques"
      ],
      "metadata": {
        "id": "iORYHnn23BiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize by words"
      ],
      "metadata": {
        "id": "ilDnlKL83JI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "filename = keras.utils.get_file(\n",
        "    origin=\"https://www.gutenberg.org/files/2701/old/moby10b.txt\",\n",
        ")\n",
        "moby_dick = list(open(filename, \"r\"))\n",
        "\n",
        "# word vocabulary:\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"multi_hot\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "\n",
        ")\n",
        "text_vectorization.adapt(moby_dick)\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Vocabulary length:\", len(vocabulary))\n",
        "print(\"Vocabulary start:\", vocabulary[:20])\n",
        "print(\"Vocabulary end:\", vocabulary[-20:])\n",
        "print(\"Processed Sentence length\", len(text_vectorization(test_sentence)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8olZGupznMS",
        "outputId": "1363a3d4-f7f1-431f-f02b-a7c319711926"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 20187\n",
            "Vocabulary start: ['[UNK]', np.str_('the'), np.str_('of'), np.str_('and'), np.str_('a'), np.str_('to'), np.str_('in'), np.str_('that'), np.str_('his'), np.str_('it'), np.str_('i'), np.str_('but'), np.str_('he'), np.str_('is'), np.str_('as'), np.str_('with'), np.str_('was'), np.str_('for'), np.str_('all'), np.str_('this')]\n",
            "Vocabulary end: [np.str_('115'), np.str_('114'), np.str_('113'), np.str_('112'), np.str_('111'), np.str_('110'), np.str_('11'), np.str_('109'), np.str_('108'), np.str_('107'), np.str_('106'), np.str_('105'), np.str_('10440'), np.str_('104'), np.str_('103'), np.str_('102'), np.str_('101'), np.str_('100000000'), np.str_('10000'), np.str_('100')]\n",
            "Processed Sentence length 20187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize by characters\n",
        "\n"
      ],
      "metadata": {
        "id": "ycG0qvL13Qsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize by characters\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"multi_hot\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    split=\"character\",\n",
        ")\n",
        "text_vectorization.adapt(moby_dick)\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "print(\"Vocabulary length:\", len(vocabulary))\n",
        "print(\"Vocabulary start:\", vocabulary[:20])\n",
        "print(\"Vocabulary end:\", vocabulary[-20:])\n",
        "print(\"Processed Sentence length\", len(text_vectorization(test_sentence)))"
      ],
      "metadata": {
        "id": "nulHGih_3RLM",
        "outputId": "4d061898-cb2f-4390-ee6e-303ae8163833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 39\n",
            "Vocabulary start: ['[UNK]', np.str_(' '), np.str_('e'), np.str_('t'), np.str_('a'), np.str_('o'), np.str_('n'), np.str_('i'), np.str_('s'), np.str_('h'), np.str_('r'), np.str_('l'), np.str_('d'), np.str_('u'), np.str_('m'), np.str_('\\n'), np.str_('c'), np.str_('w'), np.str_('f'), np.str_('g')]\n",
            "Vocabulary end: [np.str_('g'), np.str_('p'), np.str_('y'), np.str_('b'), np.str_('v'), np.str_('k'), np.str_('q'), np.str_('x'), np.str_('j'), np.str_('z'), np.str_('0'), np.str_('1'), np.str_('2'), np.str_('8'), np.str_('3'), np.str_('7'), np.str_('5'), np.str_('9'), np.str_('4'), np.str_('6')]\n",
            "Processed Sentence length 39\n"
          ]
        }
      ]
    }
  ]
}