{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reitezuz/18NES2-2025/blob/main/week_10/text_processing_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextVectorization layer\n",
        "https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/"
      ],
      "metadata": {
        "id": "YkMIXyL-RP6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ],
      "metadata": {
        "id": "NqFbf3_8xjTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text vectorization with default standardization and split\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "'''\n",
        "keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\", # default standardization\n",
        "    split=\"whitespace\",                        # default split\n",
        "    ngrams=None,                               # None, 2, 3,...\n",
        "    output_mode=\"int\",                         # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    idf_weights=None,\n",
        "    sparse=False,\n",
        "    ragged=False,\n",
        "    encoding=\"utf-8\",\n",
        "    name=None,\n",
        "    **kwargs\n",
        ")\n",
        "'''\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    standardize=\"lower_and_strip_punctuation\", # standardization\n",
        "    split=\"whitespace\", # tokenization\n",
        "   )\n"
      ],
      "metadata": {
        "id": "2VlIZpRkwEoL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMvZtIYivNSk"
      },
      "outputs": [],
      "source": [
        "# Text vectorization with custom standardization and custom split\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "    lowercase_string = tf.strings.lower(string_tensor) # to lowercase\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")  # remove punctuation\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "    return tf.strings.split(string_tensor) # split by whitespace\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the vocabulary:"
      ],
      "metadata": {
        "id": "ararNlBxTgil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    \"The weather today is surprisingly warm.\",\n",
        "    \"Tomorrow will be much colder, according to the forecast.\",\n",
        "    \"Warm days in winter are unusual, but not impossible.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)\n"
      ],
      "metadata": {
        "id": "6skq5HIPvgYr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary:\n",
        "- word order is based on their frequency:"
      ],
      "metadata": {
        "id": "Ra28HqkrS5wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn1llI1ivnen",
        "outputId": "734240d1-61ac-41a4-8b0a-bdcadbd0a5da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('warm'),\n",
              " np.str_('the'),\n",
              " np.str_('winter'),\n",
              " np.str_('will'),\n",
              " np.str_('weather'),\n",
              " np.str_('unusual'),\n",
              " np.str_('tomorrow'),\n",
              " np.str_('today'),\n",
              " np.str_('to'),\n",
              " np.str_('surprisingly'),\n",
              " np.str_('not'),\n",
              " np.str_('much'),\n",
              " np.str_('is'),\n",
              " np.str_('in'),\n",
              " np.str_('impossible'),\n",
              " np.str_('forecast'),\n",
              " np.str_('days'),\n",
              " np.str_('colder'),\n",
              " np.str_('but'),\n",
              " np.str_('be'),\n",
              " np.str_('are'),\n",
              " np.str_('according')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize text:\n",
        "- OOV (out-of-vocabulary) words have index 1"
      ],
      "metadata": {
        "id": "77vV7KEjTAcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb_kMZXFv1ni",
        "outputId": "2d9ae863-a252-4a9a-8b5d-bd953ccc0215"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 3  6  9 14  2 20  1 14  1  7  6  9], shape=(12,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of tokenization techniques"
      ],
      "metadata": {
        "id": "iORYHnn23BiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize by words"
      ],
      "metadata": {
        "id": "ilDnlKL83JI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "filename = keras.utils.get_file(\n",
        "    origin=\"https://www.gutenberg.org/files/2701/old/moby10b.txt\",\n",
        ")\n",
        "mobydick = list(open(filename, \"r\"))\n",
        "\n",
        "# word vocabulary:\n",
        "text_vectorization = keras.layers.TextVectorization(\n",
        "    output_mode=\"multi_hot\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "\n",
        ")\n",
        "text_vectorization.adapt(mobydick)\n",
        "vocabulary_mobydick = text_vectorization.get_vocabulary()\n",
        "\n",
        "print(\"Vocabulary length:\", len(vocabulary_mobydick))\n",
        "print(\"Vocabulary start:\", vocabulary_mobydick[:20])\n",
        "print(\"Vocabulary end:\", vocabulary_mobydick[-20:])\n",
        "print(\"Processed Sentence length\", len(text_vectorization(test_sentence)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8olZGupznMS",
        "outputId": "fc1a6f1b-8707-42af-ac1c-7227e291f5ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 20187\n",
            "Vocabulary start: ['[UNK]', np.str_('the'), np.str_('of'), np.str_('and'), np.str_('a'), np.str_('to'), np.str_('in'), np.str_('that'), np.str_('his'), np.str_('it'), np.str_('i'), np.str_('but'), np.str_('he'), np.str_('is'), np.str_('as'), np.str_('with'), np.str_('was'), np.str_('for'), np.str_('all'), np.str_('this')]\n",
            "Vocabulary end: [np.str_('115'), np.str_('114'), np.str_('113'), np.str_('112'), np.str_('111'), np.str_('110'), np.str_('11'), np.str_('109'), np.str_('108'), np.str_('107'), np.str_('106'), np.str_('105'), np.str_('10440'), np.str_('104'), np.str_('103'), np.str_('102'), np.str_('101'), np.str_('100000000'), np.str_('10000'), np.str_('100')]\n",
            "Processed Sentence length 20187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize by characters\n",
        "\n"
      ],
      "metadata": {
        "id": "ycG0qvL13Qsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize by characters\n",
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"multi_hot\",  # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    split=\"character\",\n",
        ")\n",
        "text_vectorization.adapt(mobydick)\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "print(\"Vocabulary length:\", len(vocabulary))\n",
        "print(\"Vocabulary start:\", vocabulary[:20])\n",
        "print(\"Vocabulary end:\", vocabulary[-20:])\n",
        "print(\"Processed Sentence length\", len(text_vectorization(test_sentence)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nulHGih_3RLM",
        "outputId": "cec63c95-6b88-4bdb-df5d-9eaca3420740"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length: 39\n",
            "Vocabulary start: ['[UNK]', np.str_(' '), np.str_('e'), np.str_('t'), np.str_('a'), np.str_('o'), np.str_('n'), np.str_('i'), np.str_('s'), np.str_('h'), np.str_('r'), np.str_('l'), np.str_('d'), np.str_('u'), np.str_('m'), np.str_('\\n'), np.str_('c'), np.str_('w'), np.str_('f'), np.str_('g')]\n",
            "Vocabulary end: [np.str_('g'), np.str_('p'), np.str_('y'), np.str_('b'), np.str_('v'), np.str_('k'), np.str_('q'), np.str_('x'), np.str_('j'), np.str_('z'), np.str_('0'), np.str_('1'), np.str_('2'), np.str_('8'), np.str_('3'), np.str_('7'), np.str_('5'), np.str_('9'), np.str_('4'), np.str_('6')]\n",
            "Processed Sentence length 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different vectorization modes"
      ],
      "metadata": {
        "id": "hd73TMUt3u6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed-length sequences of indices (truncated / with padding)"
      ],
      "metadata": {
        "id": "naTK2eF8Gq67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\", # default standardization\n",
        "    split=\"whitespace\",                        # default split, can be \"character\"\n",
        "    ngrams=None,                               # None, 2, 3,...\n",
        "    output_mode=\"int\",                         # \"int\", \"multi_hot\", \"count\" or \"tf_idf\"\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    idf_weights=None,\n",
        "    sparse=False,\n",
        "    ragged=False,\n",
        "    encoding=\"utf-8\",\n",
        "    name=None,\n",
        "    **kwargs\n",
        ")\n",
        "'''\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "max_length = 5    # Maximum length of each sequence (longer sequences will be truncated)\n",
        "max_tokens = 6    # Number of (most important) tokens\n",
        "\n",
        "text_vectorization_1 = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",                 # Convert text to sequences of integer indices\n",
        "    output_sequence_length=max_length, # Ensure sequences have the given fixed length\n",
        ")\n",
        "\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n",
        "\n",
        "test_sentence = \"Nice weather.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n"
      ],
      "metadata": {
        "id": "WFgJLI322RVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc20d581-23be-4e93-8419-c8756cb0af97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter'), np.str_('will')] \n",
            " 6\n",
            "tf.Tensor([3 1 1 1 2], shape=(5,), dtype=int64)\n",
            "tf.Tensor([1 1 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag-of-Words"
      ],
      "metadata": {
        "id": "-4qEa-FkG4zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multi_hot\n",
        "rom keras import layers\n",
        "\n",
        "max_tokens = 6    # Number of (most important) tokens\n",
        "\n",
        "text_vectorization_1 = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n",
        "\n",
        "test_sentence = \"Nice weather.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn1kLV_0G4JB",
        "outputId": "887626a7-74de-4897-a604-9b0c8e5c8c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter'), np.str_('will'), np.str_('weather')] \n",
            " 6\n",
            "tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)\n",
            "tf.Tensor([1 0 0 0 0 1], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count\n",
        "from keras import layers\n",
        "\n",
        "max_tokens = 6    # Number of (most important) tokens\n",
        "\n",
        "text_vectorization_1 = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"count\",\n",
        ")\n",
        "\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n",
        "\n",
        "test_sentence = \"Nice weather.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eLkkUOPOcM1",
        "outputId": "c23bce0e-e199-420f-f2bc-ae0ca2eda53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter'), np.str_('will'), np.str_('weather')] \n",
            " 6\n",
            "tf.Tensor([8 1 1 0 0 2], shape=(6,), dtype=int64)\n",
            "tf.Tensor([1 0 0 0 0 1], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "from keras import layers\n",
        "\n",
        "max_tokens = 6    # Number of (most important) tokens\n",
        "\n",
        "text_vectorization_1 = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"tf_idf\"\n",
        ")\n",
        "\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n",
        "\n",
        "test_sentence = \"Nice weather.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsXD-MJCQRpV",
        "outputId": "8033006f-e6c4-4c92-f6a7-5178457a6987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter'), np.str_('will'), np.str_('weather')] \n",
            " 6\n",
            "tf.Tensor([6.6162667 0.6931472 0.6931472 0.        0.        1.8325815], shape=(6,), dtype=float32)\n",
            "tf.Tensor([0.82703334 0.         0.         0.         0.         0.91629076], shape=(6,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag-of-words: Bigrams"
      ],
      "metadata": {
        "id": "a911wF8lHjyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-hot + bigrams\n",
        "from keras import layers\n",
        "\n",
        "max_tokens = 6    # Number of (most important) tokens\n",
        "\n",
        "text_vectorization_1 = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"multi_hot\",\n",
        "    ngrams = 2\n",
        "\n",
        ")\n",
        "\n",
        "text_vectorization_1.adapt(dataset)\n",
        "vocabulary = text_vectorization_1.get_vocabulary()\n",
        "print(vocabulary, \"\\n\", len(vocabulary))\n",
        "\n",
        "test_sentence = \"The weather today is warm, but it is raining. Unusual weather today.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)\n",
        "\n",
        "test_sentence = \"The weather will be nice.\"\n",
        "encoded_sentence = text_vectorization_1(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYQht8ABHiUQ",
        "outputId": "08466f19-001c-4c98-f76a-c2349f14cffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', np.str_('warm'), np.str_('the'), np.str_('winter are'), np.str_('winter'), np.str_('will be')] \n",
            " 6\n",
            "tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)\n",
            "tf.Tensor([1 0 1 0 0 1], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}